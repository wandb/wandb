version: 2.1

orbs:
  win: circleci/windows@5.0.0
  slack: circleci/slack@4.10.1
  go: circleci/go@1.7.1
  gcloud: circleci/gcp-cli@3.0.1
  gke: circleci/gcp-gke@2.0.0

parameters:
  manual:
    type: boolean
    default: false
  manual_test:
    type: boolean
    default: false
  manual_win:
    type: boolean
    default: false
  manual_mac:
    type: boolean
    default: false
  manual_test_image:
    type: string
    default: "python:3.7"
  manual_test_toxenv:
    type: string
    default: "py37"
  manual_win_toxenv:
    type: string
    default: "py37"
  manual_mac_toxenv:
    type: string
    default: "py37"
  manual_test_name:
    type: string
    default: "man-lin-py37"
  manual_win_name:
    type: string
    default: "man-win-py37"
  manual_mac_name:
    type: string
    default: "man-mac-py37"
  manual_parallelism:
    type: integer
    default: 1
  manual_xdist:
    type: integer
    default: 1
  tox_version:
    type: string
    default: "3.24.0"
  container_registry:
    type: string
    default: "gcr.io"
  gcp_cluster_name:
    type: string
    default: "sdk-nightly"
  manual_nightly:
    type: boolean
    default: false
  manual_nightly_git_branch:
    type: string
    default: main
  manual_nightly_slack_notify:
    type: boolean
    default: false
  manual_nightly_execute_shard_standalone_cpu:
    type: boolean
    default: false
  manual_nightly_execute_shard_standalone_gpu:
    type: boolean
    default: false
  manual_nightly_execute_shard_standalone_tpu:
    type: boolean
    default: false
  manual_nightly_execute_shard_standalone_local:
    type: boolean
    default: false
  manual_nightly_execute_shard_kfp:
    type: boolean
    default: false
  manual_nightly_execute_shard_standalone_gpu_win:
    type: boolean
    default: false
  manual_nightly_execute_shard_imports:
    type: boolean
    default: false
  wandb_server_tag:
    type: string
    default: "master"

commands:
  save-test-results:
    description: "Save test results"
    steps:
      - unless:
          condition: << pipeline.parameters.manual >>
          steps:
            - store_test_results:
                path: test-results
            - store_artifacts:
                path: test-results
            - store_artifacts:
                path: mypy-results
            - store_artifacts:
                path: cover-results

  setup_docker_buildx:
    description: Enable remote docker, and install the expanded `buildx` command for the CLI. Only works on alpine-based images.
    parameters:
      docker_layer_caching:
        type: boolean
        default: false
    steps:
      - setup_remote_docker:
          version: 20.10.12
          docker_layer_caching: << parameters.docker_layer_caching >>
      - run: apk add docker-cli-buildx --repository=http://dl-cdn.alpinelinux.org/alpine/edge/community

  setup_gcloud:
    parameters:
      cluster:
        description: "cluster name"
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
    steps:
      - run:
          name: "Setup gcloud and kubectl"
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud --quiet components update
            gcloud --quiet components install gke-gcloud-auth-plugin
            gcloud --quiet components install kubectl
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project $GOOGLE_PROJECT_ID
            gcloud --quiet config set compute/zone $GOOGLE_COMPUTE_ZONE
            gcloud auth configure-docker --quiet << pipeline.parameters.container_registry >>
          environment:
            GKE_CLUSTER_NAME: <<parameters.cluster >>

  create_gke_cluster:
    parameters:
      cluster:
        description: "cluster name"
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
      no-output-timeout:
        description: >
          Elapsed time that the cluster creation command can run on CircleCI without
          output. The string is a decimal with unit suffix, such as “20m”, “1.25h”,
          “5s”
        type: string
        default: 15m
      num_nodes:
        description: "Number of nodes to create"
        type: integer
        default: 1
      machine_type:
        description: "GKE cluster machine type"
        type: string
        default: "n1-standard-8"
      disk_size:
        description: "GKE cluster disk size"
        type: integer
        default: 100
      disk_type:
        description: "GKE cluster disk type"
        type: string
        default: "pd-ssd"
      gpu_type:
        description: "GKE cluster GPU type"
        type: string
        default: "nvidia-tesla-t4"
      gpu_count:
        description: "GKE cluster GPU count"
        type: integer
        default: 2
    steps:
      - setup_gcloud
      - run:
          name: "Check if cluster exists and delete if it does"
          command: |
            cluster_exists=$(gcloud container clusters list --filter="name=<< parameters.cluster >>" --format="value(name)" | wc -l | xargs)
            gcloud container clusters list --filter="name=<< parameters.cluster >>" --format="value(name)"
            if [ $? -eq 0 ] && [ $cluster_exists -eq 1 ]; then
              gcloud container clusters delete << parameters.cluster >> --quiet
            fi
            exit 0
      - run:
          name: "Create GKE cluster"
          command: |
            gcloud container clusters create $GKE_CLUSTER_NAME \
            --num-nodes=<< parameters.num_nodes >> --machine-type=<< parameters.machine_type >> \
            --disk-size=<< parameters.disk_size >> --disk-type=<< parameters.disk_type >> \
            --accelerator=type=<< parameters.gpu_type >>,count=<< parameters.gpu_count >>
          environment:
            GKE_CLUSTER_NAME: << parameters.cluster >>
          no_output_timeout: << parameters.no-output-timeout>>

  get_gke_cluster_credentials:
    parameters:
      cluster:
        description: "cluster name"
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
    steps:
      - run:
          name: "Get gke cluster credentials"
          command: |
            gcloud container clusters get-credentials << parameters.cluster >>
          environment:
            GKE_CLUSTER_NAME: << parameters.cluster >>

jobs:
  tox-base:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 7
      toxenv:
        type: string
      shard:
        type: string
        default: "base"
      notify_on_failure:
        type: boolean
        default: false
      notify_on_failure_channel:
        type: string
        default: "$SLACK_SDK_NIGHTLY_CI_CHANNEL"
      parallelism:
        type: integer
        default: 1
      execute:
        type: boolean
        default: true
    docker:
      - image: "python:<<parameters.python_version_major>>.<<parameters.python_version_minor>>"
    parallelism: << parameters.parallelism >>
    resource_class: xlarge
    working_directory: /mnt/ramdisk
    steps:
      - checkout
      - when:
          condition: << parameters.execute >>
          steps:
            - run:
                name: Install system deps
                command: |
                  apt-get update && apt-get install -y libsndfile1 ffmpeg
            - run:
                name: Install python dependencies
                command: |
                  pip install tox==<< pipeline.parameters.tox_version >>
                  pip install -U pip
                no_output_timeout: 5m
            - run:
                name: Run tests
                no_output_timeout: 10m
                command: |
                  CI_PYTEST_SPLIT_ARGS="--splits $CIRCLE_NODE_TOTAL --group $(( $CIRCLE_NODE_INDEX + 1 ))" tox -v -e << parameters.toxenv >>
            - save-test-results
            # conditionally post a notification to slack if the job failed
            - when:
                condition: << parameters.notify_on_failure >>
                steps:
                  - slack/notify:
                      event: fail
                      template: basic_fail_1
                      mentions: "@channel"
                      # taken from slack-secrets context
                      channel: << parameters.notify_on_failure_channel >>

  pytest:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 7
      toxenv:
        type: string
      notify_on_failure:
        type: boolean
        default: false
      xdist:
        type: integer
        default: 6
      test_path:
        type: string
        default: tests/unit_tests
    docker:
      - image: "python:<<parameters.python_version_major>>.<<parameters.python_version_minor>>"
      - image: gcr.io/wandb-production/local-testcontainer:<< pipeline.parameters.wandb_server_tag >>
        auth:
          username: _json_key
          password: $GCP_SERVICE_ACCOUNT_JSON_DECODED
        environment:
          CI: 1
          WANDB_ENABLE_TEST_CONTAINER: true
    resource_class: xlarge
    working_directory: /mnt/ramdisk
    steps:
      - checkout
      - run:
          name: Install system deps
          command: |
            apt-get update && apt-get install -y libsndfile1 ffmpeg
      - run:
          name: Install python dependencies
          command: |
            pip install tox==<< pipeline.parameters.tox_version >>
            pip install -U pip
            while ! curl http://localhost:8080/healthz; do sleep 1; done
          no_output_timeout: 5m
      - run:
          name: Run tests
          no_output_timeout: 10m
          command: |
            CI_PYTEST_PARALLEL=<< parameters.xdist >> \
            tox -v -e <<parameters.toxenv>>  \
              -- --wandb-server-tag << pipeline.parameters.wandb_server_tag >> << parameters.test_path >>
      - save-test-results
      # conditionally post a notification to slack if the job failed
      - when:
          condition: << parameters.notify_on_failure >>
          steps:
            - slack/notify:
                event: fail
                template: basic_fail_1
                mentions: "@channel"
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

  pex:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 8
    docker:
      - image: "python:<<parameters.python_version_major>>.<<parameters.python_version_minor>>"
    resource_class: small
    working_directory: /mnt/ramdisk
    steps:
      - checkout
      - run:
          name: Install system deps
          command: |
            apt-get update && apt-get install -y libsndfile1 ffmpeg
      - run:
          name: Install pex
          command: |
            pip install -U pip
            pip install pex
          no_output_timeout: 5m
      - run:
          name: Run pex test
          no_output_timeout: 5m
          command: |
            pex . -o wandb.pex
            WANDB_EXECUTABLE=./wandb.pex ./wandb.pex -c "import wandb; import os; wandb.init(mode='offline'); wandb.finish()"
      - save-test-results

  protobuf-compatability:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 8
    docker:
      - image: "python:<<parameters.python_version_major>>.<<parameters.python_version_minor>>"
    resource_class: small
    working_directory: /mnt/ramdisk
    steps:
      - checkout
      - run:
          name: Install system deps
          command: |
            apt-get update && apt-get install -y libsndfile1 ffmpeg
      - run:
          name: Check protobuf version compatibility
          command: |
            pip install -U pip
            pip install .
            python tools/check-protobuf-version-compatibility.py
          no_output_timeout: 5m
      - save-test-results

  win:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 9
      toxenv:
        type: string
      parallelism:
        type: integer
        default: 4
      xdist:
        type: integer
        default: 3
      machine_executor:
        type: string
        default: "default"  # "default" or "server-2019-cuda"
      executor_size:
        type: string
        default: "large"  # could only be "medium" for "server-2019-cuda"
      execute:
        type: boolean
        default: true
    executor:
      name: win/<< parameters.machine_executor >>
      size: << parameters.executor_size >>
    parallelism: << parameters.parallelism >>
    steps:
      - checkout
      - when:
          condition: << parameters.execute >>
          steps:
            - run:
                name: Install python dependencies
                shell: bash.exe
                command: |
                  pip install tox==<< pipeline.parameters.tox_version >>
            - run:
                name: Temporary conda hack
                shell: bash.exe
                command: |
                  cp /c/tools/miniconda3/python* /c/tools/miniconda3/lib/venv/scripts/nt/
            - when:
                condition:
                  equal: [ "server-2019-cuda", << parameters.machine_executor >> ]
                steps:
                  - run:
                      name: Update tox.ini on a GPU machine to install the proper pytorch version
                      shell: bash.exe
                      command: |
                        CUDA_VERSION=`ls "/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA"`
                        CUDA_VERSION_NO_DOT=`echo "${CUDA_VERSION//./}"`
                        v=${CUDA_VERSION_NO_DOT:1}
                        sed -i -e "s/whl\/cpu/whl\/cu$v/g" tox.ini
            - run:
                name: Run tests
                shell: bash.exe
                command: |
                  echo $GCLOUD_SERVICE_KEY > key.json
                  gcloud auth activate-service-account --key-file=key.json
                  yes | gcloud auth configure-docker
                  DATE=$(date -u +%Y%m%d) CI_PYTEST_PARALLEL=<< parameters.xdist >> CI_PYTEST_SPLIT_ARGS="--splits $CIRCLE_NODE_TOTAL --group $(( $CIRCLE_NODE_INDEX + 1 ))" tox -v -e << parameters.toxenv >>
                no_output_timeout: 10m
            - save-test-results

  mac:
    parameters:
      python_version_major:
        type: integer
        default: 3
      python_version_minor:
        type: integer
        default: 7
      toxenv:
        type: string
      parallelism:
        type: integer
        default: 4
      xdist:
        type: integer
        default: 3
    macos:
      xcode: 13.4.1
    resource_class: large
    parallelism: << parameters.parallelism >>
    steps:
      - checkout
      - run:
          name: Install python dependencies
          command: |
            pip3 install tox==<< pipeline.parameters.tox_version >>
      - run:
          name: Run tests
          # Tests failed with Too many open files, so added ulimit
          command: |
            ulimit -n 4096
            CI_PYTEST_PARALLEL=<< parameters.xdist >> CI_PYTEST_SPLIT_ARGS="--splits $CIRCLE_NODE_TOTAL --group $(( $CIRCLE_NODE_INDEX + 1 ))" python3 -m tox -v -e << parameters.toxenv >>
          no_output_timeout: 10m
      - save-test-results

  launch:
    parameters:
      toxenv:
        type: string
    machine:
      image: ubuntu-2004:202104-01
      docker_layer_caching: true
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - checkout
      - run:
          name: Install python dependencies, build r2d
          command: |
            pip3 install tox==<< pipeline.parameters.tox_version >>
            pip3 install chardet
            pip3 install iso8601
      - run:
          name: pull base docker images
          command: |
            docker pull nvidia/cuda:10.0-runtime
            docker pull python:3.6-buster
      - run:
          name: Run tests
          command: |
            python3 -m tox -vv -e << parameters.toxenv >>
          no_output_timeout: 10m
      - save-test-results

  kfp:
    parameters:
      toxenv:
        type: string
      execute:
        type: boolean
        default: true
      notify_on_failure:
        type: boolean
        default: true
      notify_on_success:
        type: boolean
        default: false
    machine:
      image: ubuntu-2004:2022.04.1
      docker_layer_caching: true
    resource_class: large
    steps:
      - attach_workspace:
          at: .
      - checkout
      - when:
          condition: << parameters.execute >>
          steps:
            - run:
                name: Install system deps
                command: sudo apt update && sudo apt-get install -y libsndfile1 ffmpeg
            - run:
                name: Use py37
                command: |
                  pyenv install -s 3.7.13
                  pyenv versions
                  pyenv global 3.7.13
            - run:
                name: Install python dependencies
                command: |
                  pip install --upgrade pip
                  pip install tox==<< pipeline.parameters.tox_version >>
            - run:
                name: Install kubectl
                command: |
                  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
                  sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
            - run:
                name: Install kind
                command: |
                  curl -Lo ./kind/kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64 --create-dirs
                  chmod +x ./kind/kind
                  export PATH="./kind:$PATH"
                  kind create cluster
            - run:
                name: Install KFP
                command: |
                  export PIPELINE_VERSION=1.7.1
                  kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION"
                  sleep 10s
                  kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
                  kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=$PIPELINE_VERSION"
                  sleep 10s
                  kubectl wait --for condition=ready --timeout=300s pods -n kubeflow --all
                  kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80 &
            - run:
                name: Run tests
                command: |
                  tox -v -e << parameters.toxenv >>
                no_output_timeout: 25m
            # conditionally post a notification to slack if the job failed/succeeded
            - when:
                condition: << parameters.notify_on_failure >>
                steps:
                  - slack/notify:
                      event: fail
                      template: basic_fail_1
                      mentions: "@channel"
                      # taken from slack-secrets context
                      channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL
            - when:
                condition: << parameters.notify_on_success >>
                steps:
                  - slack/notify:
                      event: pass
                      template: basic_success_1
                      # taken from slack-secrets context
                      channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL
            - save-test-results

  slack_notify:
    parameters:
      message:
        type: string
        default: ":runner:"
      execute:
        type: boolean
        default: true
    docker:
      - image: "cimg/base:stable"
    steps:
      - when:
          condition: << parameters.execute >>
          steps:
            - slack/notify:
                custom: |
                  {
                    "blocks": [
                      {
                        "type": "section",
                        "fields": [
                          {
                            "type": "plain_text",
                            "text": "<< parameters.message >>",
                            "emoji": true
                          }
                        ]
                      }
                    ]
                  }
                event: always
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL
      # this is to make sure `steps` is not empty
      - run:
          name: Print message to stdout
          command: echo << parameters.message >>

  # Build the docker image for a yea shard of the nightly workflow.
  sdk_docker:
    parameters:
      description:
        type: string
      path:
        type: string
      image_name:
        type: string
      python_version:
        type: string
        default: "3.9"
      git_branch:
        type: string
        default: "main"
      execute:
        type: boolean
        default: true
      notify_on_failure:
        type: boolean
        default: false
    docker:
      - image: "google/cloud-sdk:alpine"
    steps:
      - checkout
      - when:
          condition: << parameters.execute >>
          steps:
            - gcloud/install
#                version: "413.0.0"
#                components: "docker-credential-gcr"
            - setup_gcloud
            - setup_docker_buildx:
                docker_layer_caching: false
            - run:
                name: "Build << parameters.description >>"
                command: |
                  cd << parameters.path >>
                  docker build \
                    -t << parameters.image_name >> \
                    --build-arg PYTHON_VERSION=<< parameters.python_version >> \
                    --build-arg GIT_BRANCH=<< parameters.git_branch >> \
                    --build-arg UTC_DATE=$(date -u +%Y%m%d) \
                    .
            - run:
                name: "Push << parameters.description >> to container registry"
                command: |
                  docker push << parameters.image_name >>
            # todo: clean up old images in gcr.io
      # conditionally post a notification to slack if the job failed
      - when:
          condition: << parameters.notify_on_failure >>
          steps:
            - slack/notify:
                event: fail
                template: basic_fail_1
                mentions: "@channel"
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

  # Nightly workflow for the SDK.
  #  - spin_up_cluster job creates a GKE cluster
  #  - individual test jobs use the cluster created by the spin_up_cluster job
  #     - each requires spin_up_cluster to be run first
  #     - each runs in parallel
  #     - installs gcloud and gke and spins up a pod, deploys the test,
  #       then polls the pod for results, and finally deletes the pod
  #  - shut_down_cluster job that deletes the cluster created by the spin_up_cluster job
  #     - requires spin_up_cluster to be run first
  #     -

  # manage cluster: spin it up and shut it down
  spin_up_cluster:
    parameters:
      cluster:
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
      notify_on_failure:
        type: boolean
        default: false
    docker:
      - image: "cimg/base:stable"
    steps:
      - checkout
      - go/install
      - gcloud/install
      - setup_gcloud
      - create_gke_cluster:
          cluster: << parameters.cluster >>
      - get_gke_cluster_credentials:
          cluster: << parameters.cluster >>
      - run:
          name: "Install GPU drivers"
          command: |
            kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded-latest.yaml
      # conditionally post a notification to slack if the job failed
      - when:
          condition: << parameters.notify_on_failure >>
          steps:
            - slack/notify:
                event: fail
                template: basic_fail_1
                mentions: "@channel"
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

  shut_down_cluster:
    parameters:
      cluster:
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
      sleep_time: # time in seconds to wait before re-checking pod status
        type: integer
        default: 30
      notify_on_failure:
        type: boolean
        default: false
    docker:
      - image: "cimg/base:stable"
    steps:
      - checkout
      - go/install
      - gcloud/install
      - setup_gcloud
      - get_gke_cluster_credentials:
          cluster: << parameters.cluster >>
      - run:
          # todo: think about how to check statuses of pods before deleting cluster
          name: "Wait for pods to finish"
          command: |
            echo "Waiting for pods to finish"
            sleep 300
            count_all_pods_terminated=0
            while true; do
              kubectl get pods
              terminated_pods=`kubectl get pods --field-selector=status.phase!=Succeeded,status.phase!=Failed 2>&1`
              all_pods_terminated=`echo $(echo $terminated_pods | grep -c "No resources found")`
              if [ "$all_pods_terminated" -eq "1" ]; then
                count_all_pods_terminated=$((count_all_pods_terminated + 1))
                echo "All pods have terminated ($count_all_pods_terminated)"
                # make sure we have seen all pods terminated twice to give pod attach a chance to run
                if [ $count_all_pods_terminated -ge 2 ]; then break; fi
              fi
              sleep << parameters.sleep_time >>
            done
          no_output_timeout: "25m"
      - run:
          name: "Delete cluster"
          command: gcloud container clusters delete << parameters.cluster >>
          when: always
          no_output_timeout: "10m"
      # conditionally post a notification to slack if the job failed
      - when:
          condition: << parameters.notify_on_failure >>
          steps:
            - slack/notify:
                event: fail
                template: basic_fail_1
                mentions: "@channel"
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

  cloud_test:
    parameters:
      cluster:
        type: string
        default: << pipeline.parameters.gcp_cluster_name >>
      image_name:
        type: string
      path:
        type: string
      pod_config_name:
        type: string
        default: pod.yaml
      pod_name: # same as in <path>/pod.yaml
        type: string
      sleep_time: # time in seconds to wait before re-checking pod status
        type: integer
        default: 5
      notify_on_failure:
        type: boolean
        default: true
      notify_on_success:
        type: boolean
        default: false
      execute:
        type: boolean
        default: true
    docker:
      - image: "cimg/base:stable"
    steps:
      - checkout
      - when:
          condition: << parameters.execute >>
          steps:
            - go/install
            - gcloud/install
            - setup_gcloud
            - get_gke_cluster_credentials:
                cluster: << parameters.cluster >>
            - run:
                name: "Propagate the WANDB_API_KEY environment variable to pod.yaml"
                command: |
                  sed -i -e 's/WANDB_API_KEY_PLACEHOLDER/'"$WANDB_API_KEY"'/g' << parameters.path >>/<< parameters.pod_config_name >>
            - run:
                name: "Spin up pod"
                command: |
                  kubectl apply -f << parameters.path >>/<< parameters.pod_config_name >>
            - run:
                name: "Wait for pod to be up and running"
                command: |
                  while true; do
                    kubectl get pods
                    pod_state=$(kubectl get pods | grep << parameters.pod_name >>)
                    if [ "$(echo "$pod_state" | grep -c 'Running')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> is ready"
                      exit 0
                    elif [ "$(echo "$pod_state" | grep -c 'Completed')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> has completed"
                      exit 0
                    elif [ "$(echo "$pod_state" | grep -c 'Error')" -eq "1" ] || [ "$(echo "$pod_state" | grep -c 'CrashLoopBackOff')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> is in an error state"
                      kubectl logs << parameters.pod_name >>
                      exit 1
                    fi
                    sleep << parameters.sleep_time >>
                  done
                no_output_timeout: "5m"
            - run:
                name: "Wait for tests to finish"
                command: |
                  sleep 30

                  while true; do
                    kubectl get pods
                    pod_state=$(kubectl get pods | grep << parameters.pod_name >>)
                    if [ "$(echo "$pod_state" | grep -c 'Running')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> is running"
                    elif [ "$(echo "$pod_state" | grep -c 'Completed')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> has completed"
                      break
                    elif [ "$(echo "$pod_state" | grep -c 'Error')" -eq "1" ] || [ "$(kubectl get pods | grep -c 'CrashLoopBackOff')" -eq "1" ]; then
                      echo "Pod for << parameters.image_name >> is in an error state"
                      kubectl logs << parameters.pod_name >>
                      exit 1
                    fi
                    echo "Sleeping for << parameters.sleep_time >> seconds"
                    echo
                    sleep << parameters.sleep_time >>
                  done
                no_output_timeout: "20m"
            - run:
                name: "Grab results"
                command: |
                  # grab result data
                  echo "Launch attach pod to get results..."
                  kubectl create -f << parameters.path >>/attach.yaml
                  while true; do
                    kubectl get pods
                    pod_state=$(kubectl get pods | grep << parameters.pod_name >>-attach-pod)
                    if [ "$(echo "$pod_state" | grep -c 'Running')" -eq "1" ]; then
                      echo "Attach Pod for << parameters.image_name >> is running"
                      break
                    elif [ "$(echo "$pod_state" | grep -c 'Completed')" -eq "1" ]; then
                      echo "Attach Pod for << parameters.image_name >> has completed"
                      break
                    elif [ "$(echo "$pod_state" | grep -c 'Error')" -eq "1" ] || [ "$(kubectl get pods | grep -c 'CrashLoopBackOff')" -eq "1" ]; then
                      echo "Attach Pod for << parameters.image_name >> is in an error state"
                      kubectl logs << parameters.pod_name >>-attach-pod
                      echo "About to exit"
                      exit 1
                    fi
                    echo "Sleeping for << parameters.sleep_time >> seconds"
                    echo
                    sleep << parameters.sleep_time >>
                  done
                  echo "Copy results from pod..."
                  mkdir -p results/<< parameters.pod_name >>
                  kubectl cp << parameters.pod_name >>-attach-pod:/wandb-store/test-results results/<< parameters.pod_name >>
                  echo "Delete attach pod..."
                  kubectl delete pod << parameters.pod_name >>-attach-pod
                no_output_timeout: "10m"
            - run:
                # todo: make getting the exit_code more robust: add check for "commands succeeded"
                name: "Get pod logs and parse exit code"
                command: |
                  kubectl logs << parameters.pod_name >>
                  logs=`kubectl logs << parameters.pod_name >>`
                  exit_code=`echo $(echo $logs | grep -c "commands failed")`
                  echo "Pod for << parameters.image_name >> exited with code ${exit_code}"
                  exit ${exit_code}
                no_output_timeout: "20m"
            - store_test_results:
                path: results/<< parameters.pod_name >>/test-results
            - store_artifacts:
                path: results/<< parameters.pod_name >>/test-results
                destination: test-results
            - run:
                name: "Delete the pod"
                when: always
                command: |
                  kubectl get pods
                  kubectl delete -f << parameters.path >>/<< parameters.pod_config_name >> || echo "Problem deleting pod"
                  kubectl delete -f << parameters.path >>/attach.pod || echo "Problem deleting attach pod"
            # conditionally post a notification to slack if the job failed/succeeded
            - when:
                condition: << parameters.notify_on_failure >>
                steps:
                  - slack/notify:
                      event: fail
                      template: basic_fail_1
                      mentions: "@channel"
                      # taken from slack-secrets context
                      channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL
            - when:
                condition: << parameters.notify_on_success >>
                steps:
                  - slack/notify:
                      event: pass
                      template: basic_success_1
                      # taken from slack-secrets context
                      channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

  pip_install_wandb:
    parameters:
      python_version:
        type: string
      notify_on_failure:
        type: boolean
        default: true
      notify_on_success:
        type: boolean
        default: false
    docker:
      - image: "python:<< parameters.python_version >>"
    steps:
      - run:
          name: "Install stable version of wandb with stable versions of dependencies"
          command: |
            pip install wandb
            python -c "import wandb"
            pip freeze > deps_wandb.txt
            pip uninstall -y -r deps_wandb.txt
          when: always
      - run:
          name: "Install pre-release version of wandb with stable versions of dependencies"
          command: |
            pip install --pre wandb
            python -c "import wandb"
            pip freeze > deps_wandb_pre.txt
            pip uninstall -y -r deps_wandb_pre.txt
          when: always
      - run:
          name: "Install stable version of wandb with pre-release versions of dependencies"
          command: |
            wget https://raw.githubusercontent.com/wandb/wandb/$CIRCLE_BRANCH/requirements.txt
            for r in `grep -o '^[^(#,;)]*' requirements.txt`; do pip install --upgrade --pre "$r"; done
            pip install wandb
            python -c "import wandb"
            pip freeze > deps_wandb_deps_pre.txt
            pip uninstall -y -r deps_wandb_deps_pre.txt
          when: always
      - run:
          name: "Install pre-release version of wandb with pre-release versions of dependencies"
          command: |
            for r in `grep -o '^[^(#,;)]*' requirements.txt`; do pip install --upgrade --pre "$r"; done
            pip install --pre wandb
            python -c "import wandb"
          when: always

      # conditionally post a notification to slack if the job failed/succeeded
      - when:
          condition: << parameters.notify_on_failure >>
          steps:
            - slack/notify:
                event: fail
                template: basic_fail_1
                mentions: "@channel"
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL
      - when:
          condition: << parameters.notify_on_success >>
          steps:
            - slack/notify:
                event: pass
                template: basic_success_1
                # taken from slack-secrets context
                channel: $SLACK_SDK_NIGHTLY_CI_CHANNEL

workflows:
  nightly:
    when:
      and:
        - equal:
            - << pipeline.trigger_source >>
            - scheduled_pipeline
        - equal:
            - << pipeline.schedule.name >>
            - "nightly"
    jobs:
      #
      # kfp tests
      #
      - kfp:
          name: "mach-kubeflow"
          toxenv: "func-s_kfp-py37"
          context: slack-secrets
          notify_on_failure: true
      #
      # import tests
      #
      - tox-base:
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 7, 8 ]
              shard:
                - "imports1"
                - "imports2"
                - "imports3"
                - "imports4"
                - "imports5"
                - "imports6"
                - "imports7"
                - "imports8"
                - "imports9"
                - "imports10"
                - "imports11"
                - "imports12"
          name: "func-s_<<matrix.shard>>-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "func-s_<<matrix.shard>>-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          context: slack-secrets
          notify_on_failure: true
          notify_on_failure_channel: $SLACK_SDK_NIGHTLY_CI_GROWTH_CHANNEL
      #
      # protobuf compatibility tests
      #
      - protobuf-compatability:
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 7, 8, 9, 10 ]
          name: "protobuf-compatability-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
      #
      # standalone GPU tests on Windows
      #
      - win:
          machine_executor: "server-2019-cuda"
          executor_size: "medium"
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 9 ]
          name: "func-s_standalone_gpu-win-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "standalone-gpu-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          parallelism: 2
          xdist: 1
      #
      # standalone tests on gke
      #
      - slack_notify:
          name: "slack-notify-on-start"
          context: slack-secrets
          # todo? add a link to the pipeline in the message
          message: ":runner: *Nightly run started!*"
      # check that `pip install wandb` is successful
      - pip_install_wandb:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8", "3.9", "3.10", "3.11"]
          context: slack-secrets
          notify_on_failure: true
          requires:
            - "slack-notify-on-start"
      # build docker images for yea shards
      - sdk_docker:
          name: "build-cpu-docker-image"
          description: "SDK Docker image for CPU testing"
          path: "./tests/standalone_tests/shards/gke_cpu"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/cpu-sdk:latest
          requires:
            - "slack-notify-on-start"
          context: slack-secrets
          notify_on_failure: true
      - sdk_docker:
          name: "build-gpu-docker-image"
          description: "SDK Docker image for GPU testing"
          path: "./tests/standalone_tests/shards/gke_gpu"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/gpu-sdk:latest
          requires:
            - "slack-notify-on-start"
          context: slack-secrets
          notify_on_failure: true
      # manage the gke cluster
      - spin_up_cluster:
          requires:
            - "slack-notify-on-start"
          context: slack-secrets
          notify_on_failure: true
      - shut_down_cluster:
          requires:
            - spin_up_cluster
          context: slack-secrets
          notify_on_failure: true
      # run the tests
      - cloud_test:
          name: "cloud-test-cpu"
          requires:
            - "build-cpu-docker-image"
            - spin_up_cluster
          path: "./tests/standalone_tests/shards/gke_cpu"
          pod_name: "cpu-pod"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/cpu-sdk:latest
          context: slack-secrets
          notify_on_failure: true
          notify_on_success: true
      - cloud_test:
          name: "cloud-test-gpu"
          requires:
            - "build-gpu-docker-image"
            - spin_up_cluster
          path: "./tests/standalone_tests/shards/gke_gpu"
          pod_name: "gpu-pod"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/gpu-sdk:latest
          context: slack-secrets
          notify_on_failure: true
          notify_on_success: true
      - slack_notify:
          name: "slack-notify-on-finish"
          context: slack-secrets
          requires:
            - shut_down_cluster
          message: ":checkered_flag: *Nightly run finished!*"

  main:
    when:
      and:
        - not:
            equal:
              - scheduled_pipeline
              - << pipeline.trigger_source >>
        - not: << pipeline.parameters.manual >>
    jobs:
      #
      # Linting
      #
      - tox-base:
          name: "code-check"
          python_version_minor: 8
          toxenv: "protocheck3,protocheck4,generatecheck,codecovcheck,mypy,mypy-report,pyupgrade,black,isort-check,flake8,docstrings"
      #
      # Unit tests with pytest on Linux, using real wandb server
      #
      - pytest:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [6, 7, 8, 9, 10]
          name: "unit-s_base-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "py<<matrix.python_version_major>><<matrix.python_version_minor>>,covercircle"
      #
      # Unit tests with pytest on Linux, using the old mock server
      #
      - tox-base:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [6, 7, 8, 9, 10]
          name: "unit-s_base_mock_server-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "py<<matrix.python_version_major>><<matrix.python_version_minor>>,covercircle"
      #
      # Unit tests with pytest on Linux, using real wandb server -- for launch (unit_tests/tests_launch)
      #
      - pytest:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [8]
          name: "unit-s_base-lin-pylaunch<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "pylaunch<<matrix.python_version_major>><<matrix.python_version_minor>>,covercircle"
          test_path: "tests/unit_tests/tests_launch"

      #
      # Functional tests with yea on Linux (base only)
      #
      - tox-base:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [7]
              shard:
                - "base"
          name: "func-s_<<matrix.shard>>-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "func-s_<<matrix.shard>>-py<<matrix.python_version_major>><<matrix.python_version_minor>>,func-covercircle"
          parallelism: 4
      #
      # Functional tests with yea on Linux
      #
      - tox-base:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [7]
              shard:
                - "sklearn"
                - "metaflow"
                - "tf115"
                - "tf21"
                - "tf24"
                - "tf25"
                - "tf26"
                - "ray112"
                - "ray2"
                - "service"
                - "noml"
                - "grpc"
                - "docs"
          name: "func-s_<<matrix.shard>>-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "func-s_<<matrix.shard>>-py<<matrix.python_version_major>><<matrix.python_version_minor>>,func-covercircle"
      #
      # Functional tests with yea on Windows
      #
      - win:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [9]
          name: "func-s_base-win-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "func-s_base-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          parallelism: 6
          xdist: 1
      #
      # Unit tests with pytest on Windows and MacOS, using real wandb server
      #
      - win:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [9]
          name: "unit-s_base-win-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "py<<matrix.python_version_major>><<matrix.python_version_minor>>,wincovercircle -- --timeout 300 tests/unit_tests"
      - mac:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [9]
          name: "unit-s_base_mock_server-mac-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "py<<matrix.python_version_major>><<matrix.python_version_minor>>,covercircle"
      #
      # wandb launch tests
      #
      - launch:
          name: "mach-launch"
          toxenv: "pylaunch,covercircle"
      #
      # sharded unit tests
      #
      # s_nb: notebook tests
      - tox-base:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [6]
          name: "unit-s_nb-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "unit-s_nb-py<<matrix.python_version_major>><<matrix.python_version_minor>>,unit-covercircle"
      - win:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [9]
          name: "unit-s_nb-win-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "unit-s_nb-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          parallelism: 1
          xdist: 1
      - mac:
          matrix:
            parameters:
              python_version_major: [3]
              python_version_minor: [9]
          name: "unit-s_nb-mac-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "unit-s_nb-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          parallelism: 1
          xdist: 1
      #
      # pex test
      #
      - pex:
          name: "pex"


  # todo: needs love
  #  manual_test:
  #    when: << pipeline.parameters.manual_test >>
  #    jobs:
  #      - test:
  #          name: << pipeline.parameters.manual_test_name >>
  #          image: << pipeline.parameters.manual_test_image >>
  #          toxenv: << pipeline.parameters.manual_test_toxenv >>
  #          parallelism: << pipeline.parameters.manual_parallelism >>
  #          xdist: << pipeline.parameters.manual_xdist >>
  #
  #  manual_win:
  #    when: << pipeline.parameters.manual_win >>
  #    jobs:
  #      - win:
  #          name: << pipeline.parameters.manual_win_name >>
  #          toxenv: << pipeline.parameters.manual_win_toxenv >>
  #          parallelism: << pipeline.parameters.manual_parallelism >>
  #          xdist: << pipeline.parameters.manual_xdist >>
  #
  #  manual_mac:
  #    when: << pipeline.parameters.manual_mac >>
  #    jobs:
  #      - mac:
  #          name: << pipeline.parameters.manual_mac_name >>
  #          toxenv: << pipeline.parameters.manual_mac_toxenv >>
  #          parallelism: << pipeline.parameters.manual_parallelism >>
  #          xdist: << pipeline.parameters.manual_xdist >>

  manual_nightly:
    when: << pipeline.parameters.manual_nightly >>
    jobs:
      #
      # kfp tests
      #
      - kfp:
          name: "mach-kubeflow"
          toxenv: "func-s_kfp-py37"
          execute: << pipeline.parameters.manual_nightly_execute_shard_kfp >>
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
      #
      # import tests
      #
      - tox-base:
          execute: << pipeline.parameters.manual_nightly_execute_shard_imports >>
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 7, 8 ]
              shard:
                - "imports1"
                - "imports2"
                - "imports3"
                - "imports4"
                - "imports5"
                - "imports6"
                - "imports7"
                - "imports8"
                - "imports9"
                - "imports10"
                - "imports11"
                - "imports12"
          name: "func-s_<<matrix.shard>>-lin-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "func-s_<<matrix.shard>>-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          context: slack-secrets
          notify_on_failure: true
          notify_on_failure_channel: $SLACK_SDK_NIGHTLY_CI_GROWTH_CHANNEL
      #
      # protobuf compatibility tests
      #
      - protobuf-compatability:
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 7, 8, 9, 10 ]
          name: "protobuf-compatability-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
      #
      # standalone GPU tests on Windows
      #
      - win:
          machine_executor: "server-2019-cuda"
          executor_size: "medium"
          execute: << pipeline.parameters.manual_nightly_execute_shard_standalone_gpu_win >>
          matrix:
            parameters:
              python_version_major: [ 3 ]
              python_version_minor: [ 9 ]
          name: "func-s_standalone_gpu-win-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          toxenv: "standalone-gpu-py<<matrix.python_version_major>><<matrix.python_version_minor>>"
          parallelism: 2
          xdist: 1
      #
      # standalone tests on gke
      #
      - slack_notify:
          name: "slack-notify-on-start"
          context: slack-secrets
          # todo? add a link to the pipeline in the message
          message: ":runner: *Manual cloud run started!*"
          execute: << pipeline.parameters.manual_nightly_slack_notify >>
      # check that `pip install wandb` is successful
      - pip_install_wandb:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8", "3.9", "3.10", "3.11"]
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
          requires:
            - "slack-notify-on-start"
      # build docker images for yea shards
      - sdk_docker:
          name: "build-cpu-docker-image"
          description: "SDK Docker image for CPU testing"
          git_branch: << pipeline.parameters.manual_nightly_git_branch >>
          path: "./tests/standalone_tests/shards/gke_cpu"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/cpu-sdk:latest
          requires:
            - "slack-notify-on-start"
          execute: << pipeline.parameters.manual_nightly_execute_shard_standalone_cpu >>
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
      - sdk_docker:
          name: "build-gpu-docker-image"
          description: "SDK Docker image for GPU testing"
          git_branch: << pipeline.parameters.manual_nightly_git_branch >>
          path: "./tests/standalone_tests/shards/gke_gpu"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/gpu-sdk:latest
          requires:
            - "slack-notify-on-start"
          execute: << pipeline.parameters.manual_nightly_execute_shard_standalone_gpu >>
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
      # manage the gke cluster
      - spin_up_cluster:
          requires:
            - "slack-notify-on-start"
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
      - shut_down_cluster:
          requires:
            - spin_up_cluster
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
      # run the tests
      - cloud_test:
          name: "cloud-test-cpu"
          requires:
            - "build-cpu-docker-image"
            - spin_up_cluster
          path: "./tests/standalone_tests/shards/gke_cpu"
          pod_name: "cpu-pod"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/cpu-sdk:latest
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
          notify_on_success: << pipeline.parameters.manual_nightly_slack_notify >>
          execute: << pipeline.parameters.manual_nightly_execute_shard_standalone_cpu >>
      - cloud_test:
          name: "cloud-test-gpu"
          requires:
            - "build-gpu-docker-image"
            - spin_up_cluster
          path: "./tests/standalone_tests/shards/gke_gpu"
          pod_name: "gpu-pod"
          image_name: << pipeline.parameters.container_registry >>/${GOOGLE_PROJECT_ID}/gpu-sdk:latest
          context: slack-secrets
          notify_on_failure: << pipeline.parameters.manual_nightly_slack_notify >>
          notify_on_success: << pipeline.parameters.manual_nightly_slack_notify >>
          execute: << pipeline.parameters.manual_nightly_execute_shard_standalone_gpu >>
      - slack_notify:
          execute: << pipeline.parameters.manual_nightly_slack_notify >>
          name: "slack-notify-on-finish"
          context: slack-secrets
          requires:
            - shut_down_cluster
          message: ":checkered_flag: *Manual cloud run finished!*"
